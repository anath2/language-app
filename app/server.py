import io
import os
import unicodedata
from pathlib import Path
from contextlib import asynccontextmanager
from threading import Lock

import dspy
from PIL import Image as PILImage
from dotenv import load_dotenv
from fastapi import FastAPI, File, Form, HTTPException, Request, UploadFile
from fastapi.responses import HTMLResponse, RedirectResponse, StreamingResponse
import json
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel

from enum import IntEnum

from app.auth import (
    AuthMiddleware,
    get_session_manager,
    verify_password,
)
from app.persistence import (
    create_event,
    create_text,
    get_due_count,
    get_review_queue,
    get_text,
    get_vocab_srs_info,
    init_db,
    record_lookup,
    record_review_grade,
    save_vocab_item,
    update_vocab_status,
)

# Load environment variables
load_dotenv()

# Configure DSPy with OpenRouter
openrouter_model = os.getenv("OPENROUTER_MODEL")
openrouter_api_key = os.getenv("OPENROUTER_API_KEY")

if not openrouter_api_key:
    raise ValueError("OPENROUTER_API_KEY environment variable is required")

lm = dspy.LM(
    model=f"openrouter/{openrouter_model}",
    api_key=openrouter_api_key,
)
dspy.configure(lm=lm)

# Lifespan context manager for startup/shutdown events
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Validate required auth environment variables
    if not os.getenv("APP_PASSWORD"):
        raise ValueError("APP_PASSWORD environment variable is required")
    if not os.getenv("APP_SECRET_KEY"):
        raise ValueError("APP_SECRET_KEY environment variable is required")

    # Startup: Initialize database
    init_db()
    yield
    # Shutdown: Nothing needed currently


# Initialize FastAPI app
app = FastAPI(title="Language App", version="1.0.0", lifespan=lifespan)

# Add authentication middleware
app.add_middleware(AuthMiddleware)

# Configure static files and templates
BASE_DIR = Path(__file__).resolve().parent
app.mount("/static", StaticFiles(directory=BASE_DIR / "static"), name="static")
templates = Jinja2Templates(directory=BASE_DIR / "templates")

# Initialize pipeline with thread-safe lazy initialization
_pipeline_lock = Lock()
pipeline = None
_full_translation_lock = Lock()
full_translation_model = None


def get_pipeline():
    """Thread-safe lazy initialization of pipeline"""
    global pipeline
    if pipeline is None:
        with _pipeline_lock:
            if pipeline is None:
                pipeline = Pipeline()
    return pipeline


def get_full_translator():
    """Thread-safe lazy initialization for full-text translation"""
    global full_translation_model
    if full_translation_model is None:
        with _full_translation_lock:
            if full_translation_model is None:
                full_translation_model = dspy.ChainOfThought(FullTranslator)
    return full_translation_model


# Request/Response Models
class TranslateRequest(BaseModel):
    text: str


class TranslationResult(BaseModel):
    segment: str
    pinyin: str
    english: str


class ParagraphResult(BaseModel):
    translations: list[TranslationResult]
    separator: str


class TranslateResponse(BaseModel):
    paragraphs: list[ParagraphResult]


# Persistence API models
class CreateTextRequest(BaseModel):
    raw_text: str
    source_type: str = "text"  # 'text' | 'ocr'
    metadata: dict = {}


class CreateTextResponse(BaseModel):
    id: str


class TextResponse(BaseModel):
    id: str
    created_at: str
    source_type: str
    raw_text: str
    normalized_text: str
    metadata: dict


class CreateEventRequest(BaseModel):
    event_type: str
    text_id: str | None = None
    segment_id: str | None = None
    payload: dict = {}


class CreateEventResponse(BaseModel):
    id: str


class SaveVocabRequest(BaseModel):
    headword: str
    pinyin: str = ""
    english: str = ""
    text_id: str | None = None
    segment_id: str | None = None
    snippet: str | None = None
    status: str = "learning"  # unknown|learning|known


class SaveVocabResponse(BaseModel):
    vocab_item_id: str


class UpdateVocabStatusRequest(BaseModel):
    vocab_item_id: str
    status: str  # unknown|learning|known


class OkResponse(BaseModel):
    ok: bool = True


# SRS API models
class ReviewGrade(IntEnum):
    AGAIN = 0
    HARD = 1
    GOOD = 2


class RecordLookupRequest(BaseModel):
    vocab_item_id: str


class RecordLookupResponse(BaseModel):
    vocab_item_id: str
    opacity: float
    is_struggling: bool


class VocabSRSInfoResponse(BaseModel):
    vocab_item_id: str
    headword: str
    pinyin: str
    english: str
    opacity: float
    is_struggling: bool
    status: str  # unknown|learning|known


class VocabSRSInfoListResponse(BaseModel):
    items: list[VocabSRSInfoResponse]


class ReviewCardResponse(BaseModel):
    vocab_item_id: str
    headword: str
    pinyin: str
    english: str
    snippets: list[str]


class ReviewQueueResponse(BaseModel):
    cards: list[ReviewCardResponse]
    due_count: int


class ReviewAnswerRequest(BaseModel):
    vocab_item_id: str
    grade: ReviewGrade


class ReviewAnswerResponse(BaseModel):
    vocab_item_id: str
    next_due_at: str | None
    interval_days: float
    remaining_due: int


class DueCountResponse(BaseModel):
    due_count: int


# Signature Definitions
class Segmenter(dspy.Signature):
    """Segment Chinese text into words"""

    text: str = dspy.InputField(description="Chinese text to segment")
    segments: list[str] = dspy.OutputField(description="List of words")


class Translator(dspy.Signature):
    """Translate Chinese words to Pinyin and English"""

    segment: str = dspy.InputField(description="A segment of chinese text to translate")
    context: str = dspy.InputField(description="Context of the translation task")
    pinyin: str = dspy.OutputField(
        description="Pinyin transliteration of the segment"
    )
    english: str = dspy.OutputField(
        description="English translation of the segment"
    )


class FullTranslator(dspy.Signature):
    """Translate full Chinese text into English for reference"""

    text: str = dspy.InputField(description="Full Chinese text to translate")
    english: str = dspy.OutputField(description="English translation of the full text")


class OCRExtractor(dspy.Signature):
    """Extract Chinese text from an image"""

    image: dspy.Image = dspy.InputField(description="Image containing Chinese text")
    chinese_text: str = dspy.OutputField(
        description="Extracted Chinese text from the image"
    )


# Image validation constants
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB
ALLOWED_EXTENSIONS = {".png", ".jpg", ".jpeg", ".webp", ".gif"}


def validate_image_file(file_bytes: bytes, filename: str) -> tuple[bool, str | None]:
    """Validate uploaded image file"""
    if len(file_bytes) > MAX_FILE_SIZE:
        return False, "File too large. Maximum size is 5MB"
    ext = Path(filename).suffix.lower()
    if ext not in ALLOWED_EXTENSIONS:
        return False, f"Unsupported file type. Allowed: {', '.join(ALLOWED_EXTENSIONS)}"
    return True, None


async def extract_text_from_image(image_bytes: bytes) -> str:
    """Extract Chinese text from image using the configured LM"""
    pil_image = PILImage.open(io.BytesIO(image_bytes))
    original_format = pil_image.format

    # Formats supported by vision APIs - no conversion needed
    supported_formats = {"JPEG", "PNG", "WEBP", "GIF"}

    if original_format in supported_formats:
        # Use original bytes directly if format is supported
        # Only need to handle RGBA/P mode conversion for JPEG
        if original_format == "JPEG" and pil_image.mode in ("RGBA", "P"):
            pil_image = pil_image.convert("RGB")
            buffer = io.BytesIO()
            pil_image.save(buffer, format="JPEG", quality=85)
            normalized_bytes = buffer.getvalue()
        else:
            normalized_bytes = image_bytes
    else:
        # Convert unsupported formats (MPO, BMP, TIFF, etc.) to JPEG
        if pil_image.mode in ("RGBA", "P"):
            pil_image = pil_image.convert("RGB")
        buffer = io.BytesIO()
        pil_image.save(buffer, format="JPEG", quality=85)
        normalized_bytes = buffer.getvalue()

    image = dspy.Image(normalized_bytes)
    extractor = dspy.ChainOfThought(OCRExtractor)
    result = await extractor.acall(image=image)
    return result.chinese_text


def should_skip_translation(segment: str) -> bool:
    """
    Check if a segment should skip translation.
    Returns True if segment contains only:
    - Whitespace
    - ASCII punctuation/symbols
    - ASCII digits
    - Chinese punctuation
    - Full-width numbers and symbols
    """
    if not segment or not segment.strip():
        return True

    # Define Chinese punctuation marks
    chinese_punctuation = "。，、；：？！""''（）【】《》…—·「」『』〈〉〔〕"

    for char in segment:
        # Skip whitespace
        if char.isspace():
            continue

        # Check if it's ASCII punctuation, symbol, or digit
        if char.isascii() and not char.isalpha():
            continue

        # Check if it's Chinese punctuation
        if char in chinese_punctuation:
            continue

        # Check if it's a full-width number or symbol (Unicode category)
        category = unicodedata.category(char)
        if category in ('Nd', 'No', 'Po', 'Ps', 'Pe', 'Pd', 'Pc', 'Sk', 'Sm', 'So'):
            # Nd: Decimal number, No: Other number
            # Po: Other punctuation, Ps: Open punctuation, Pe: Close punctuation
            # Pd: Dash punctuation, Pc: Connector punctuation
            # Sk: Modifier symbol, Sm: Math symbol, So: Other symbol
            continue

        # If we found a character that's not punctuation/number/symbol, don't skip
        return False

    # All characters are punctuation/numbers/symbols
    return True


def split_into_paragraphs(text: str) -> list[dict[str, str]]:
    """
    Split text into paragraphs while preserving whitespace information.
    Returns a list of dicts with 'content' and 'separator' keys.
    The separator indicates what whitespace follows this paragraph.
    """
    if not text:
        return []

    # Split by newlines while keeping track of the separators
    lines = text.split('\n')
    paragraphs = []

    for i, line in enumerate(lines):
        # Skip completely empty lines at the start
        if not paragraphs and not line.strip():
            continue

        # For non-empty lines, add them as paragraphs
        if line.strip():
            # Determine the separator by looking ahead
            # Count consecutive newlines after this line
            separator = '\n'
            j = i + 1
            while j < len(lines) and not lines[j].strip():
                separator += '\n'
                j += 1

            paragraphs.append({
                'content': line.strip(),
                'separator': separator if i < len(lines) - 1 else ''
            })

    return paragraphs


# Pipeline Definition
class Pipeline(dspy.Module):
    """Pipeline for Chinese text processing"""

    def __init__(self):
        self.segment = dspy.ChainOfThought(Segmenter)
        self.translate = dspy.Predict(Translator)

    def forward(self, text: str) -> list[tuple[str, str, str]]:
        """Sync: Segment and translate Chinese text"""
        segmentation = self.segment(text=text)

        result = []
        for segment in segmentation.segments:
            # Skip translation for segments with only symbols, numbers, and punctuation
            if should_skip_translation(segment):
                result.append((segment, "", ""))
            else:
                translation = self.translate(segment=segment, context=text)
                result.append((segment, translation.pinyin, translation.english))
        return result

    async def aforward(self, text: str) -> list[tuple[str, str, str]]:
        """Async: Segment and translate Chinese text"""
        segmentation = await self.segment.acall(text=text)

        result = []
        for segment in segmentation.segments:
            # Skip translation for segments with only symbols, numbers, and punctuation
            if should_skip_translation(segment):
                result.append((segment, "", ""))
            else:
                translation = await self.translate.acall(segment=segment, context=text)
                result.append((segment, translation.pinyin, translation.english))
        return result


# API Endpoints
@app.get("/health")
async def health_check():
    """Health check endpoint for monitoring"""
    return {"status": "ok"}


# --- Authentication Routes ---
@app.get("/login", response_class=HTMLResponse)
async def login_page(request: Request):
    """Serve the login page."""
    # If already authenticated, redirect to home
    session_token = request.cookies.get("session")
    if session_token and get_session_manager().verify_session(session_token):
        return RedirectResponse(url="/", status_code=303)
    return templates.TemplateResponse(request=request, name="login.html")


@app.post("/login", response_class=HTMLResponse)
async def login_submit(request: Request, password: str = Form(...)):
    """Handle login form submission."""
    if not verify_password(password):
        return templates.TemplateResponse(
            request=request,
            name="fragments/login_error.html",
            context={"message": "Invalid password"},
            status_code=401,
        )

    response = RedirectResponse(url="/", status_code=303)
    get_session_manager().set_session_cookie(response)
    return response


@app.post("/logout")
async def logout():
    """Clear session cookie and redirect to login."""
    response = RedirectResponse(url="/login", status_code=303)
    get_session_manager().clear_session_cookie(response)
    return response


@app.get("/", response_class=HTMLResponse)
async def homepage(request: Request):
    """Serve the main page with the translation form"""
    return templates.TemplateResponse(request=request, name="index.html")


# --- Persistence API (Milestone 0) ---
@app.post("/api/texts", response_model=CreateTextResponse)
async def api_create_text(request: CreateTextRequest):
    if not request.raw_text.strip():
        raise HTTPException(status_code=400, detail="raw_text is required")
    record = create_text(
        raw_text=request.raw_text, source_type=request.source_type, metadata=request.metadata
    )
    return CreateTextResponse(id=record.id)


@app.get("/api/texts/{text_id}", response_model=TextResponse)
async def api_get_text(text_id: str):
    record = get_text(text_id)
    if record is None:
        raise HTTPException(status_code=404, detail="Not found")
    return TextResponse(
        id=record.id,
        created_at=record.created_at,
        source_type=record.source_type,
        raw_text=record.raw_text,
        normalized_text=record.normalized_text,
        metadata=record.metadata,
    )


@app.post("/api/events", response_model=CreateEventResponse)
async def api_create_event(request: CreateEventRequest):
    if not request.event_type.strip():
        raise HTTPException(status_code=400, detail="event_type is required")
    event_id = create_event(
        event_type=request.event_type,
        text_id=request.text_id,
        segment_id=request.segment_id,
        payload=request.payload,
    )
    return CreateEventResponse(id=event_id)


@app.post("/api/vocab/save", response_model=SaveVocabResponse)
async def api_save_vocab(request: SaveVocabRequest):
    if not request.headword.strip():
        raise HTTPException(status_code=400, detail="headword is required")
    if request.status not in {"unknown", "learning", "known"}:
        raise HTTPException(status_code=400, detail="Invalid status")
    vocab_item_id = save_vocab_item(
        headword=request.headword.strip(),
        pinyin=request.pinyin.strip(),
        english=request.english.strip(),
        text_id=request.text_id,
        segment_id=request.segment_id,
        snippet=request.snippet,
        status=request.status,
    )
    return SaveVocabResponse(vocab_item_id=vocab_item_id)


@app.post("/api/vocab/status", response_model=OkResponse)
async def api_update_vocab_status(request: UpdateVocabStatusRequest):
    try:
        update_vocab_status(vocab_item_id=request.vocab_item_id, status=request.status)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e)) from e
    return OkResponse()


# --- SRS API (Milestone 1) ---
@app.post("/api/vocab/lookup", response_model=RecordLookupResponse)
async def api_record_lookup(request: RecordLookupRequest):
    """Record a passive lookup event for a vocab item."""
    result = record_lookup(request.vocab_item_id)
    if result is None:
        raise HTTPException(status_code=404, detail="Vocab item not found")
    return RecordLookupResponse(
        vocab_item_id=result.vocab_item_id,
        opacity=result.opacity,
        is_struggling=result.is_struggling,
    )


@app.get("/api/vocab/srs-info", response_model=VocabSRSInfoListResponse)
async def api_get_vocab_srs_info(headwords: str):
    """Get SRS info for a comma-separated list of headwords."""
    if not headwords.strip():
        return VocabSRSInfoListResponse(items=[])

    headword_list = [h.strip() for h in headwords.split(",") if h.strip()]
    results = get_vocab_srs_info(headword_list)

    return VocabSRSInfoListResponse(
        items=[
            VocabSRSInfoResponse(
                vocab_item_id=r.vocab_item_id,
                headword=r.headword,
                pinyin=r.pinyin,
                english=r.english,
                opacity=r.opacity,
                is_struggling=r.is_struggling,
                status=r.status,
            )
            for r in results
        ]
    )


@app.get("/api/review/queue", response_model=ReviewQueueResponse)
async def api_get_review_queue(limit: int = 10):
    """Get vocab items due for active review."""
    cards = get_review_queue(limit=limit)
    due_count = get_due_count()

    return ReviewQueueResponse(
        cards=[
            ReviewCardResponse(
                vocab_item_id=c.vocab_item_id,
                headword=c.headword,
                pinyin=c.pinyin,
                english=c.english,
                snippets=c.snippets,
            )
            for c in cards
        ],
        due_count=due_count,
    )


@app.post("/api/review/answer", response_model=ReviewAnswerResponse)
async def api_record_review_answer(request: ReviewAnswerRequest):
    """Record a review grade for a vocab item (active review)."""
    try:
        state = record_review_grade(request.vocab_item_id, grade=int(request.grade))
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e)) from e

    if state is None:
        raise HTTPException(status_code=404, detail="Vocab item not found")

    remaining = get_due_count()

    return ReviewAnswerResponse(
        vocab_item_id=state.vocab_item_id,
        next_due_at=state.due_at,
        interval_days=state.interval_days,
        remaining_due=remaining,
    )


@app.get("/api/review/count", response_model=DueCountResponse)
async def api_get_due_count():
    """Get count of vocab items due for review."""
    return DueCountResponse(due_count=get_due_count())


@app.post("/translate-text", response_model=TranslateResponse)
async def translate_text(request: TranslateRequest):
    """Translate Chinese text to Pinyin and English"""
    pipe = get_pipeline()

    # Split text into paragraphs
    paragraphs = split_into_paragraphs(request.text)

    # Process each paragraph through the pipeline
    paragraph_results = []
    for para in paragraphs:
        results = await pipe.aforward(para['content'])
        translations = [
            TranslationResult(segment=seg, pinyin=pinyin, english=english)
            for seg, pinyin, english in results
        ]
        paragraph_results.append(
            ParagraphResult(translations=translations, separator=para['separator'])
        )

    return TranslateResponse(paragraphs=paragraph_results)


@app.post("/translate-html", response_class=HTMLResponse)
async def translate_html(request: Request, text: str = Form(...)):
    """Translate Chinese text and return HTML fragment for HTMX."""
    if not text.strip():
        return templates.TemplateResponse(
            request=request,
            name="fragments/error.html",
            context={"message": "Please enter some Chinese text"},
        )

    try:
        pipe = get_pipeline()

        # Split text into paragraphs
        paragraphs = split_into_paragraphs(text)

        # Process each paragraph through the pipeline
        paragraph_results = []
        for para in paragraphs:
            results = await pipe.aforward(para['content'])
            translations = [
                {"segment": seg, "pinyin": pinyin, "english": english}
                for seg, pinyin, english in results
            ]
            paragraph_results.append({
                "translations": translations,
                "separator": para['separator']
            })

        return templates.TemplateResponse(
            request=request,
            name="fragments/results.html",
            context={"paragraphs": paragraph_results, "original_text": text},
        )
    except Exception as e:
        return templates.TemplateResponse(
            request=request,
            name="fragments/error.html",
            context={"message": f"Translation error: {e}"},
        )


@app.post("/translate-stream")
async def translate_stream(text: str = Form(...)):
    """Stream translation progress via SSE"""

    async def generate():
        if not text.strip():
            yield f"data: {json.dumps({'type': 'error', 'message': 'Please enter some Chinese text'})}\n\n"
            return

        try:
            pipe = get_pipeline()
            full_translator = get_full_translator()

            # Full-text translation (separate from pipeline)
            full_translation_result = await full_translator.acall(text=text)
            full_translation = full_translation_result.english

            # Split text into paragraphs
            paragraphs = split_into_paragraphs(text)

            # Count total segments across all paragraphs
            all_paragraph_segments = []
            for para in paragraphs:
                segmentation = await pipe.segment.acall(text=para['content'])
                all_paragraph_segments.append({
                    'segments': segmentation.segments,
                    'separator': para['separator']
                })

            total_segments = sum(len(p['segments']) for p in all_paragraph_segments)

            # Send initial info with paragraph structure
            paragraph_info = [{'segment_count': len(p['segments']), 'separator': p['separator']} for p in all_paragraph_segments]
            yield f"data: {json.dumps({'type': 'start', 'total': total_segments, 'paragraphs': paragraph_info, 'fullTranslation': full_translation})}\n\n"

            # Step 2: Translate each segment in each paragraph
            global_index = 0
            all_results = []

            for para_idx, para_data in enumerate(all_paragraph_segments):
                para_results = []
                for seg_idx, segment in enumerate(para_data['segments']):
                    # Skip translation for segments with only symbols, numbers, and punctuation
                    if should_skip_translation(segment):
                        result = {
                            "segment": segment,
                            "pinyin": "",
                            "english": "",
                            "index": global_index,
                            "paragraph_index": para_idx,
                        }
                    else:
                        # Use the original paragraph content as context
                        context = paragraphs[para_idx]['content']
                        translation = await pipe.translate.acall(segment=segment, context=context)
                        result = {
                            "segment": segment,
                            "pinyin": translation.pinyin,
                            "english": translation.english,
                            "index": global_index,
                            "paragraph_index": para_idx,
                        }
                    para_results.append(result)
                    global_index += 1

                    # Send progress update
                    yield f"data: {json.dumps({'type': 'progress', 'current': global_index, 'total': total_segments, 'result': result})}\n\n"

                all_results.append({
                    'translations': para_results,
                    'separator': para_data['separator']
                })

            # Send completion with paragraph structure
            yield f"data: {json.dumps({'type': 'complete', 'paragraphs': all_results, 'fullTranslation': full_translation})}\n\n"

        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(generate(), media_type="text/event-stream")


@app.post("/extract-text-html", response_class=HTMLResponse)
async def extract_text_html(request: Request, file: UploadFile = File(...)):
    """HTMX endpoint for OCR extraction only - fills textarea for editing"""
    try:
        file_bytes = await file.read()

        valid, error = validate_image_file(file_bytes, file.filename or "image.png")
        if not valid:
            return templates.TemplateResponse(
                request=request,
                name="fragments/error.html",
                context={"message": error},
            )

        extracted_text = await extract_text_from_image(file_bytes)

        if not extracted_text.strip():
            return templates.TemplateResponse(
                request=request,
                name="fragments/error.html",
                context={"message": "No Chinese text found in image"},
            )

        return templates.TemplateResponse(
            request=request,
            name="fragments/ocr-result.html",
            context={"extracted_text": extracted_text},
        )
    except Exception as e:
        return templates.TemplateResponse(
            request=request,
            name="fragments/error.html",
            context={"message": f"OCR error: {e}"},
        )


@app.post("/translate-image", response_model=TranslateResponse)
async def translate_image(file: UploadFile = File(...)):
    """Extract Chinese text from image and translate"""
    file_bytes = await file.read()

    valid, error = validate_image_file(file_bytes, file.filename or "image.png")
    if not valid:
        raise HTTPException(status_code=400, detail=error)

    extracted_text = await extract_text_from_image(file_bytes)

    if not extracted_text.strip():
        raise HTTPException(status_code=400, detail="No Chinese text found in image")

    pipe = get_pipeline()

    # Split text into paragraphs
    paragraphs = split_into_paragraphs(extracted_text)

    # Process each paragraph through the pipeline
    paragraph_results = []
    for para in paragraphs:
        results = await pipe.aforward(para['content'])
        translations = [
            TranslationResult(segment=seg, pinyin=pinyin, english=english)
            for seg, pinyin, english in results
        ]
        paragraph_results.append(
            ParagraphResult(translations=translations, separator=para['separator'])
        )

    return TranslateResponse(paragraphs=paragraph_results)


@app.post("/translate-image-html", response_class=HTMLResponse)
async def translate_image_html(request: Request, file: UploadFile = File(...)):
    """HTMX endpoint for image translation"""
    try:
        file_bytes = await file.read()

        valid, error = validate_image_file(file_bytes, file.filename or "image.png")
        if not valid:
            return templates.TemplateResponse(
                request=request,
                name="fragments/error.html",
                context={"message": error},
            )

        extracted_text = await extract_text_from_image(file_bytes)

        if not extracted_text.strip():
            return templates.TemplateResponse(
                request=request,
                name="fragments/error.html",
                context={"message": "No Chinese text found in image"},
            )

        pipe = get_pipeline()

        # Split text into paragraphs
        paragraphs = split_into_paragraphs(extracted_text)

        # Process each paragraph through the pipeline
        paragraph_results = []
        for para in paragraphs:
            results = await pipe.aforward(para['content'])
            translations = [
                {"segment": seg, "pinyin": pinyin, "english": english}
                for seg, pinyin, english in results
            ]
            paragraph_results.append({
                "translations": translations,
                "separator": para['separator']
            })

        return templates.TemplateResponse(
            request=request,
            name="fragments/results.html",
            context={"paragraphs": paragraph_results, "original_text": extracted_text},
        )
    except Exception as e:
        return templates.TemplateResponse(
            request=request,
            name="fragments/error.html",
            context={"message": f"OCR error: {e}"},
        )
